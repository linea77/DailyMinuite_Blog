---
title: Convolutional Neural Networks for Sentence Classification_Yoon Kim
categories: [papers]
comments: false
---

## **🚩 목차**

---

- [Abstract](#abstract)
- [1. Introduction](#1-introduction)
- [2. Model](#2-model)
  - [2.1. Regularization](#21-regularization)
- [3. Datasets and Experimental Setup](#3-datasets-and-experimental-setup)
  - [3.1. Hyperparameters and Training](#31-hyperparameters-and-training)
  - [3.2. Pre-trained Word Vectors](#32-pre-trained-word-vectors)
  - [3.3. Model Variations](#33-model-variations)
- [4. Results and Discussion](#4-results-and-discussion)
  - [4.1. Multichanel vs Single Channel Models](#41-multichanel-vs-single-channel-models)
  - [4.2. Static vs Non-static Representations](#42-static-vs-non-static-representations)
  - [4.3. Further observation](#43-further-observation)
- [5. Conclusion](#5-conclusion)

# Abstract

- 사전학습된 워드벡터(word2vec)로 훈련한 CNN으로 문장단위 분류를 실험함.
- 적은 하이퍼파라미터와 static vector를 사용한 simple CNN만으로도 여러 [벤치마크](<https://ko.wikipedia.org/wiki/%EB%B2%A4%EC%B9%98%EB%A7%88%ED%81%AC_(%EC%BB%B4%ED%93%A8%ED%8C%85)>)에서 좋은 성능을 보여주었음.
- 파인튜닝으로 task-specific vector를 학습하는 것이 성능을 향상시킴
- 추가적으로 task-specific vector와 static vector를 둘 다 사용하여 조금 수정한 모델 구조 또한 제안함.
- 이 논문에서 제안한 CNN모델은 감성분석, 질문분류를 포함한 7가지의 task 중 4개에서 the state of the art(SOTA)보다 좋은 성능을 보여줌.

# 1. Introduction

**기존의 자연어처리 연구들**

<img src="https://miro.medium.com/max/828/1*C_gwJa1g_DCi3AehkXYCjQ.png" alt="https://miro.medium.com/max/828/1*C_gwJa1g_DCi3AehkXYCjQ.png" style="zoom:50%;" /> <img src="https://miro.medium.com/max/1400/1*gzXwhDnDmu60OHyEFGnF-Q.png" alt="https://miro.medium.com/max/1400/1*gzXwhDnDmu60OHyEFGnF-Q.png" style="zoom:50%;" />

[이미지 출처](https://towardsdatascience.com/visualizing-word-embedding-with-pca-and-t-sne-961a692509f5)

- neural 언어 모델을 통해 word vector representation을 학습하고, 분류를 위해 그 워드벡터들을 합성하는 방식을 많이 사용함.

- 이 때 워드벡터는 희소(sparce)한 1-of-V(V는 어휘사이즈) 인코딩 결과를, 더 낮은 차원의 은닉층을 통과하면서 단어에 대한 특징을 추출해내는 방식을 사용하였음

- 이렇게 추출된 dense representations에서는 비슷한 특징을 가진 단어끼리는 두 단어 사이의 거리가 가깝고, 서로 다른 특징을 가질 수록 그 거리가 멀어짐. (분포가설기반)

**이미지 처리를 위해 고안된 CNN이 NLP에 적용됨**

<img src="https://media2.giphy.com/media/i4NjAwytgIRDW/giphy.gif?cid=790b7611c907ea5c778c883acc2e6c05c9b414f8d112b665&rid=giphy.gif&ct=g" alt="cnn" style="zoom:50%;" />

[이미지출처](https://giphy.com/gifs/blog-daniel-keypoints-i4NjAwytgIRDW)

<img src="https://149695847.v2.pressablecdn.com/wp-content/uploads/2018/01/conv-full-layer.gif" alt="[이미지 출처](https://analyticsindiamag.com/convolutional-neural-network-image-classification-overview/)" style="zoom:50%;" />

[이미지 출처](https://analyticsindiamag.com/convolutional-neural-network-image-classification-overview/)

- 합성곱신경망(CNN)은 Computer vision 분야에서 고안된 것으로 레이어의 local features에 필터를 적용하는 방식임.

- 곧 CNN이 NLP task들에도 적용이 되었는데, 여러 task들에서 좋은 성능을 보여주었음.

**본 논문의 연구 내용**

- unsupervised neural language model에서 얻은 워드벡터에 1개의 convolution layer를 가진 CNN을 학습시킴.

- 이 워드벡터는 Google News에서 1000억개 단어로 학습된 워드벡터임.

- 이 워드벡터 값을 고정시킨 뒤 아주 적은 양의 하이퍼파라미터만 튜닝해서 학습을 진행한 결과, 훌륭한 성능을 보여주었음 ⇒ 사전학습된 워드벡터가 universal features extractors임을 확인

- 그 뒤에 task-specific하도록 파인튜닝한 결과, 성능이 더 향상되었음.

- 그 뒤, [채널](https://velog.io/@jee-9/Deep-Learning-%EA%B8%B0%EC%B4%88-Channel-Feature-Map-%EA%B0%9C%EC%9A%94)을 여러개로 만들어 사전학습된 벡터와 파인튜닝 후 task-specific 벡터를 모두 사용하도록 모델을 수정함

- 또한 image classification에 관하여, 딥러닝 모델에서 얻은 feature extractors가 original task와 차이가 있는 다른 task에서도 좋은 성능을 보여주었음을 증명하였던, Razavian et al.(2014) 연구와 철학적으로 유사함.

# 2. Model

**기본적인 모델 구조**

- 모델 구조는 Collobert et al.(2011)의 CNN 구조를 조금 변형한 형태이다.

![figure1](\assets\img\post_img\p0001\figure 1.png)

---

![Untitled](\assets\img\post_img\p0001\equation 1.png)

(1) Concatenation operation : 1번째 워드 벡터 부터 n번째 워드벡터까지를 늘어놓은 것

---

![Untitled](\assets\img\post_img\p0001\equation 2.png)

(2) Convolution operation: i번째 워드벡터부터 i+h-1번째 워드벡터를 늘어놓은 것에 크기가 h\*k인 필터 W를 곱하고 bias를 더하여 만든 i번째 feature.

![Untitled](\assets\img\post_img\p0001\equation 3.png)

(3) [feature map](https://velog.io/@jee-9/Deep-Learning-%EA%B8%B0%EC%B4%88-Channel-Feature-Map-%EA%B0%9C%EC%9A%94) :각각의 가능한 모든 단어 window에 대해 (2)를 수행하여 만든 feature map.

- 윈도우사이즈(h)가 다른 여러개의 필터를 사용하기 때문에 여러개의 features를 얻게 됨.

---

![Untitled](\assets\img\post_img\p0001\equation 4.png)

- [max-over-time pooling operation](https://stackoverflow.com/questions/48549670/pooling-vs-pooling-over-time)
- 가장 중요한 feature를 추출하기 위해 하나의 필터에 대해 하나의 최댓값만을 취함.
- (이미지는 크기가 같기 때문에) 이미지에서 일반적으로 사용하는 방법과 달리, max-over-time을 사용하는 이유는 서로 다른 길이의 문장이더라도 적용가능하기 때문임.

---

- 이 여러개의 features는 penultimate layer(맨 마지막에서 두 번째 레이어)를 구성하게 되고, fully connected softmax layer를 통과하여 확률분포를 출력하게 됨.

**Model variant; Multichannel Architecture - 두 개의 Channel 사용**

- 1 Channel of stactic word vector + 1 Channel of fine-tuned word vector
  - Static word vector : 훈련 내내 정적으로 유지되는(값이 고정되어있는) 워드벡터
  - fine-tuned word vector : 역전파(backpropagation)를 통해 파인튜닝되는(값이 업데이트되는) 워드벡터
- 각각의 필터가 두 개의 채널에 모두 적용되어 (2)Convolution operation를 계산하기 위해 서로 더해짐.
- 나머지는 single channel architecture와 동일함.

## 2.1. Regularization

1. 순전파/역전파

   ![Untitled](\assets\img\post_img\p0001\equation 5.png)

   (5) Drop out

   - penultimate layer(맨 마지막에서 두번째 레이어)에 dropout을 적용
   - feature map에 드롭아웃을 수행하는 마스킹 벡터 r을 곱함. 마스킹 되지 않은 유닛으로만 역전파가 진행됨.
   -

2. Test time

   ![Untitled](\assets\img\post_img\p0001\equation 6.png)

   - 학습되어있는 가중치 W에 p를 곱하여 스케일링한 것( $\hat{w}$ )을 unseen sentences(테스트 데이터셋)에 사용
   - 가중치 벡터에 l2-norms constraint를 줘서<img src="C:\Users\User\Desktop\Github\linea77.github.io\assets\img\post_img\p0001\inequality 1.png" alt="Untitled" style="zoom: 50%;" />일 때,

     <img src="C:\Users\User\Desktop\Github\linea77.github.io\assets\img\post_img\p0001\equation 7.png" alt="Untitled" style="zoom:50%;" />가 되도록 rescailing을 함.

# 3. Datasets and Experimental Setup

<img src="\assets\img\post_img\p0001\table 1.png" alt="Untitled" style="zoom:50%;" />

**Benchmarks**

- MR :
  - 1문장 영화 리뷰
  - positive / negative
- SST-1
  - Stanford Sentiment Treebank
  - 영화리뷰의 확장버전
  - train/dev/test splits 제공됨
  - very positive / positive / netural / negative / very negative
- SST-2
  - SST-1과 기본적으로 같음
  - positive / negative
- Subj
  - Subjectivity(주관성) 데이터셋
  - 문장이 Subjective인지 Objective인지 분류하는 태스크
- TREC
  - TREC question 데이터셋
  - 질문을 6개의 질문 타입(person, location, numeric information 등)으로 분류하는 태스크
- CR
  - 상품에 대한 고객 리뷰(Customer reviews)
  - Positive / Negative
- MPQA
  - Opinion polarity detection

## 3.1. Hyperparameters and Training

- 활성화함수 : rectified liner uitits(ReLU)

- filter window h 크기 = 3, 4, 5

- feature map 개수 = 100

- dropout rate (p) = 0.5

- l2 constraint (s) = 3

- mini-batch size = 50

(위 값들은 SST-2 dev set으로 [grid search](https://justweon-dev.tistory.com/21)를 통해 선택함)

- early stopping
  - dev set 사용
  - dev set이 없으면 training data의 10%를 랜덤하게 선택하여 dev set으로 사용
- stochastic gradient descent(확률적 경사 하강법) over shuffled mini-batches
- Adadelta

## 3.2. Pre-trained Word Vectors

- 워드벡터를 unsupervised neural language model에서 얻은 워드벡터로 초기화하는 것은, 큰 규모의 supervised training set이 없을 때 성능을 향상시키도록 많이 쓰는 방법임.
- Google NEws의 1000억개 어휘로 학습된 word2vec을 사용함.
- 워드벡터 dimensionality = 300
- Continuous bag-of-words(CBOW)사용
- 사전 학습된 어휘 집합에 없는 단어는 무작위로 초기화함(randomly initialized)

## 3.3. Model Variations

- CNN-rand
  - 모든 어휘에 대해 랜덤하게 초기화하고, 훈련을 통해 수정해나감.(사전학습된 워드벡터를 사용하지 않음)
- CNN-static
  - 사전학습된 word2vec 워드벡터와, 랜덤하게 초기화한 unknown words 모두 처음 상태 그대로 고정(static)되어있고, 다른 파라미터들만 학습됨.
- CNN-non-static
  - 사전학습된 word2vec 워드벡터와, 랜덤하게 초기화한 unknown words 워드벡터가 각각의 task에 의해 파인튜닝됨.(워드벡터가 업데이트 됨)
- CNN-multichannel
  - 두 종류의 워드벡터(static & non-static)을 사용함.
  - 각각의 집합은 channel이 되고, 각각의 필터가 두 개의 채널 모두에 적용됨
  - 그러나 non-static channel 에만 역전파가 허용됨

# 4. Results and Discussion

<img src="\assets\img\post_img\p0001\table 2.png" alt="Untitled" style="zoom: 67%;" />

- CNN-rand VS 사전학습을 사용한 모델들
  - CNN-rand는 성능이 잘 나오지 않는 반면, 사전학습된 워드벡터를 사용한 다른 모델은 훨씬 더 좋은 성능을 보여주었음
- CNN-static VS 복잡한 기법을 사용한 모델들
  - CNN-static은 간단히 사전학습된 워드벡터를 사용했을 뿐인데도, 복잡한 pooling 방식을 사용하는 모델(DCNN), 사전의 파스트리를 계산해야 하는 모델(RNTN)과 비등비등한 성능을 보여줌
- CNN-non-static
  - fine-tuning하는 것도 더 성능을 향상시킴

## 4.1. Multichanel vs Single Channel Models

- 처음에 멀티채널구조가 오버피팅(overfitting)을 막을 수 있을 것이라고 기대했고, 따라서 데이터셋이 작아지더라도 싱글채널모델보다 더 좋은 성능을 보여줄 것이라고 생각했음
- 그러나 뚜렷하게 멀티채널구조가 더 좋은 성능을 보여주진 않았으며, 성능에 대한 결과가 섞여서 나왔다.
- 따라서 fine-tuning 과정의 일반화에 대한 추가연구가 필요하다.
  - 예) 채널을 1개로 유지하되, 학습하는 동안 수정될 수 있는 추가적인 차원을 사용

## 4.2. Static vs Non-static Representations

![Untitled](\assets\img\post_img\p0001\table 3.png)

- Non-satic 채널이 다루고 있는 task에 대해 더 구체적으로 워드벡터표상을 만들어내었음
  - 기존 word2Vec에서는 통사적인 유사성(비슷한 환경에서 사용됨)에 집중하여 bad와 good을 유사한 단어로 표상하였음
  - 그러나 positive/negative의 라벨을 갖는 SST-2의 감정분석 task로 파인튜닝한 결과 bad와 good은 더이상 유사한 단어로 표상되지 않음.
- 사전학습된 워드벡터에 나타나지 않아서 랜덤하게 초기화한 경우,
  - 파인튜닝을 통해 더 의미있는 표상을 만들어낼 수 있었음.
  - 예) 콤마(,)가 접속사와 유사함을 잡아냄.

## 4.3. Further observation

- Kalchbrenner et al. (2014)에서 동일한 구조의 CNN을 사용했으나 훨씬 성능이 안좋았음
  - 필터의 사이즈를 여러개로 사용하고, 이에 따라 feature map도 여러개로 만들었기 때문에 차이가 생김
- Dropout이 좋은 정규화 도구임이 증명되었음. 지속적으로 2%~4%의 성능 향상을 보여줌
- word2vec에 없는 단어를 무작위로 초기화할 때, word2vec 벡터와 동일한 분산을 갖도록 a를 선택하고 샘플링을 해 약간의 개선을 얻었음.
- 위키피디아로 학습된 다른 워드벡터도 사용해 보았으나 word2vec이 훨씬 우수한 성능을 보여줌
- Adadelta는 Adagrad와 비슷한 결과를 보여주었으나 epoch수가 더 적게 필요했음.

# 5. Conclusion

- 하이퍼파라미터를 거의 튜닝하지 않았음에도, 하나의 레이어를 가진 simple CNN은 꽤 좋은 성능을 보여주었다.
- 또한 사전학습된 워드벡터를 사용하는 것이 자연어처리 딥러닝에서 중요함을 보여준다.
